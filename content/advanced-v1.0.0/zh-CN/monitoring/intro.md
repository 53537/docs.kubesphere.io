---
title: "监控概述"
---

## 容器平台监控面临的挑战

根据 CNCF 最新调查显示，有 38％ 的用户认为监控是其应用 Kubernetes 遇到的最大挑战之一，随着企业规模的增长，这个比例甚至达到了 46%。这其中存在的重要原因，是与传统监控相比，容器与微服务的监控面临着更多难点和考验，因为容器监控与传统监控的区别就在于：

- 监控频率不同：容器启停都是秒级，而且扩缩也非常快，对容器的系统监控要求和传统监控是不一样的，传统系统监控可能是分钟级的，容器系统监控是秒级的
- 数量级不同：传统的监控针对基础设备，数量较少，容器是运行在基础设施之上，每个节点可以支撑多个容器实例，我们监控的容器数量至少应该是之前监控设备的数十倍以上
- 更偏向应用监控：容器随时可以启停，具备可以动态扩缩容等特点，应用的健康状况对用户来说更为重要

面对动辄几百甚至上千台虚拟机、容器，和数十种要监控的对象指标，怎样的设计架构和技术方案才能满足如此庞大而繁杂的监控需求呢？现代 IT 的领导者以及 Kubernetes 用户，又如何在优化性能的同时又能简化 Kubernetes 监控，从而提高效率呢？KubeSphere 已经给出了答案。

对于企业级容器管理平台而言，全、准、快是 KubeSphere 实现多维度监控的目标，提供全面而准确的实时监控是保证平台所有容器类工作负载和服务的高可靠性、高可用性和高性能的重要部分。KubeSphere 提取了平台的物理主机和容器等各项资源运行的关键指标，以监控图表形式展示，因此用户可以非常方便地统计和收集到不同资源在不同维度的监控数据，能够在第一时间掌握资源和业务的运行情况和监控状况，快速定位故障。

收集资源的监控数据旨在帮助用户观察和建立资源和集群性能的正常标准。通过不同时间、不同负载条件下监测集群各项基础指标并收集历史监控数据，并以图表的形式展现容器集群和服务运行时的性能。例如，用户可以监控集群和节点的 CPU 利用率、内存使用率和磁盘 I/O、网卡流量等物理层级的基础指标，还可以监控平台的企业空间、容器组 (Pod) 和容器的 CPU 使用量、内存使用量等指标，以及项目资源用量和服务组件的状态。

## 监控指标

KubeSphere 的监控中心包括 [物理资源监控](../physical-resources) 和 [应用资源监控](../application-resources) 两大类。通常，只有平台管理员 (Cluster-admin) 或在该平台角色的权限列表中勾选了 **查看监控管理** 的用户，才有权限在控制台查看监控中心，详见 [物理资源监控](../physical-resources) 和 [应用资源监控](../application-resources)。

值得一提的是，监控中心支持用户按用量排序和自定义时间范围查询，帮助快速定位故障所在。

KubeSphere 对资源的监控从两条线提供多维度的监控指标，即
- 管理员视角：**Cluster -> Node -> Pod -> Container** 
- 用户视角：**Cluster -> Workspace -> Namespace -> Workload/Pod -> Container**

![监控指标](/monitor-items.svg)

从上图中不难发现，平台的监控指标和 IaaS 层相似，也就是我们常见的 CPU、内存、磁盘 和 网络等四个方面的使用量和使用率。另外，我们也提供 Inode 监控。比如有可能用户使用过程中发现 Pod 创建不成功，经过调查发现是由于 inode 满了所导致的。为什么会出现这种情况？是因为 Kubernetes 对镜像和日志都有回收机制，但是对 inode 的回收和清理是没有的，所以说 Inode 监控也是相当重要，它可能会造成你整个集群中某个节点无法创建工作负载。



## 监控技术选型

我们监控模块的设计和架构，主要是采用了开源的解决方案，大家如果关注云原生和容器监控就会了解，容器的监控基本就这么几种解决方案，我们在最初的技术选型历程，考虑了 Heapster + Elasticsearch 和 Heapster + Kafka + ClickHouse，但最后还是选择了 [Prometheus](https://prometheus.io/)。

因为调研的时候，我们发现 Heapster 要被 Metrics Server 取代，只把当前监控数据保存在内存中，需要有工具去抓取，不能再依赖 Heapster 抓取后存到各种后端存储。而选择 Prometheus 的理由不仅仅是因为它是继 Kubenetes 之后第二个从 CNCF 毕业的产品，还包括以下几点理由：

- Prometheus 和 Kubenetes 天然集成，为 CloudNative 而设计，多种工具和服务纷纷推出适配的 Exporter，供 Prometheus 抓取，接触到的信息是越来越多的人利用 Prometheus + Grafana 监控 K8S 集群，逐渐成为监控告警的首选技术
- 颠覆了传统监控系统被动等待接收数据的 Push 模式，改为主动拉数据的 Pull 模式，相当于有了数据获取 Agent 的能力
- 2.0 之后重写了底层时序数据存储层，针对时序数据特点优化，能利用更少的资源存储和查询更多的数据
- 灵活好用的查询语言 PromQL，能把 PromQL  嵌入 http 请求的强大的 API
- OpenMetrics 项目推动 Prometheus exposure format 成为监控数据的标准格式 
- Prometheus Operator 打包了 Kubernetes 监控所需的所有必要组件，更丰富的监控数据
- 单节点能处理海量数据的能力，一个 Kubernetes 集群一个 Prometheus，一个 DataCenter 一个 Prometheus 的用法经常被提到

KubeSphere 监控中心的所有组件都是容器化的并由其底层的 Kubernetes 编排，因此，在任意 Kubernetes 集群里中都可以快速部署；当系统需要变更时，只需要修改其编排模板文件即可。下图是我们目前的监控系统以及即将集成的告警模块的设计架构。

![架构](/monitoring-design.png)


## 展望未来

目前 KubeSphere 监控中心已经具备了高可用和多维度的特性。在提供了监控之后，我们将在下一个版本支持创建告警、消息通知和日志收集等功能，支持根据给定阈值每隔一段时间发送告警，比如设置告警策略类型、告警规则和接收方式。